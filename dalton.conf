[dalton]

# debug logging
DEBUG = False

# location for job .zip files on disk. Not deleted by dalton; use
#  something like a cron job to prune old files if necessary
job_path = /opt/dalton/jobs

# root directory for all the rulesets Dalton knows about.
#  inside this directory there should be a 'suricata' and
#  a 'snort' directory in which the corresponding rules go.
# it is not recommended that you change this
ruleset_path = /opt/dalton/rulesets

# temp storage for pcaps, configs, etc. Should be cleaned up by Dalton 
#  and everything in here can be deleted after the job is submitted
temp_path = /tmp/dalton

# IP/host of redis server; dalton_redis is the (resolvable)
#  hostname of the redis docker container
redis_host = dalton_redis

# location of configuration files for the sundry supported engines
# it is recommended that you NOT change this since Flask looks in 
# the static directory to serve the config files.
engine_conf_path = /opt/dalton/app/static/engine-configs

# timeout (minutes) for keys to expire in Redis for regular (non-teapot)
#  submitted jobs (7200 == 5 days)
redis_expire = 7200

# timeout (minutes) for keys to expire in Redis for teapot
#  jobs (short and stout jobs that are short lived)
teapot_redis_expire = 62

# time (seconds) for jobs to run before setting timeout status
job_run_timeout = 3600

# if a Dalton Agent has not checked into the controller in this many
#  minutes, clear it from the sensor list (which prevents jobs from
#  being submitted to that queue if there are no other sensors with
#  that engine (technology) and version.
agent_purge_time = 20

# API Keys valid for Dalton Agents (currently not used)
api_keys = bmV2ZXIgdW5kZXJlc3RpbWF0ZSB5b3VyIG9wcG9uZW50,ZXhwZWN0IHRoZSB1bmV4cGVjdGVk,dGFrZSBpdCBvdXRzaWRl,UGFpbiBkb24ndCBodXJ0

# location of mergecap binary; needed to combine multiple pcaps for Suricata jobs
mergecap_binary = /usr/bin/mergecap

# program that reads the unified2 binary files and outputs text
u2_analyzer = /usr/local/lib/python3.9/site-packages/idstools/scripts/u2spewfoo.py

# if rulecat.py (from py-idstools) exists, then Dalton will download rulesets on
#  startup iff no rulesets exist
rulecat_script = /usr/local/lib/python3.9/site-packages/idstools/scripts/rulecat.py

# On the job submission page, the number of pcaps that can be uploaded
# can be limited in the UI and when Dalton processes pcaps. This value sets
# that limit.
max_pcap_files = 10


#############
# Flowsynth #
#############

[flowsynth-web]

#path to flowsynth script for web gui
bin_path = /opt/flowsynth

#where to store PCAPs temporarily; should be considered public
pcap_path = /tmp/pcaps
